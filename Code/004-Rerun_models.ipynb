{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84fa8fab-ad53-4b2b-92fa-b7edd93422ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa71713-99c6-45d8-b92c-ca76cd9ce3e0",
   "metadata": {},
   "source": [
    "# Repeated CV con (pequeña) búsqueda por fold y recolección de métricas\n",
    "Mejoando modelos...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67700113-ad95-4b7f-a4fe-5d80997825fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats=pd.read_csv(\"../res/Features_extraction_Mantra.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bc61d55-042b-4c89-ae90-f350bc057612",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd, json, os\n",
    "from typing import Dict, Any, Tuple, List\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit, RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from joblib import parallel_backend, dump as joblib_dump\n",
    "\n",
    "# ========== Utils básicos ==========\n",
    "def _drop_constant_features(X: pd.DataFrame) -> pd.DataFrame:\n",
    "    nunq = X.nunique(dropna=True)\n",
    "    X = X.drop(columns=nunq[nunq <= 1].index.tolist(), errors='ignore')\n",
    "    var0 = X.var(axis=0, skipna=True)\n",
    "    return X.drop(columns=var0[var0 == 0].index.tolist(), errors='ignore')\n",
    "\n",
    "def _select_feature_set(fullX: pd.DataFrame, feature_set: str) -> pd.DataFrame:\n",
    "    fs = feature_set.lower()\n",
    "    cols = []\n",
    "    if fs in (\"hvg\",\"all\"):\n",
    "        cols += [c for c in fullX.columns if c.startswith(\"hvg_\")]\n",
    "    if fs in (\"dhvg\",\"all\"):\n",
    "        cols += [c for c in fullX.columns if c.startswith(\"dhvg_\")]\n",
    "    if fs in (\"whvg\",\"all\"):\n",
    "        cols += [c for c in fullX.columns if c.startswith(\"whvg_\") or c.startswith(\"wvg_\")]\n",
    "    seen = set(); cols = [c for c in cols if not (c in seen or seen.add(c))]\n",
    "    if not cols:\n",
    "        cols = [c for c in fullX.columns if c.startswith((\"hvg_\",\"dhvg_\",\"whvg_\",\"wvg_\"))]\n",
    "    return fullX[cols].copy()\n",
    "\n",
    "def _prep_feats_labels(feats: pd.DataFrame, feature_set: str):\n",
    "    assert 'Classification' in feats.columns\n",
    "    X_full = feats.drop(columns=[c for c in ['ID','Classification'] if c in feats.columns]).copy()\n",
    "    X_full = X_full.apply(pd.to_numeric, errors='coerce')\n",
    "    X_full = _drop_constant_features(X_full)\n",
    "    X = _select_feature_set(X_full, feature_set)\n",
    "    y_raw = feats['Classification'].astype(str).values\n",
    "    le = LabelEncoder(); y = le.fit_transform(y_raw)\n",
    "    return X, y, le\n",
    "\n",
    "# ========== Modelos e hiperparámetros ==========\n",
    "def _make_model_and_space(model:str, seed:int):\n",
    "    \"\"\"\n",
    "    Soporta: 'lgbm' (default), 'xgb', 'rf', 'et'\n",
    "    - Si XGBoost no está disponible, cae a RF.\n",
    "    \"\"\"\n",
    "    mdl = model.lower()\n",
    "\n",
    "    # Intentar XGBoost opcional\n",
    "    _has_xgb = True\n",
    "    try:\n",
    "        from xgboost import XGBClassifier\n",
    "    except Exception:\n",
    "        _has_xgb = False\n",
    "\n",
    "    if mdl == 'lgbm':\n",
    "        try:\n",
    "            from lightgbm import LGBMClassifier\n",
    "        except Exception:\n",
    "            mdl = 'rf'\n",
    "\n",
    "    if mdl == 'lgbm':\n",
    "        from lightgbm import LGBMClassifier\n",
    "        clf = LGBMClassifier(\n",
    "            objective='multiclass', n_estimators=800, class_weight='balanced',\n",
    "            num_leaves=31, min_child_samples=60, min_split_gain=1e-3,\n",
    "            subsample=0.8, colsample_bytree=0.8, verbose=-1, random_state=seed, device ='gpu', gpu_platform_id=0,\n",
    "    gpu_device_id=0\n",
    "        )\n",
    "        space = {\n",
    "            'clf__num_leaves': [15,31,63],\n",
    "            'clf__max_depth': [-1,6,8,12],\n",
    "            'clf__learning_rate': np.logspace(-2.3, -0.5, 8),\n",
    "            'clf__subsample': [0.7,0.8,0.9,1.0],\n",
    "            'clf__colsample_bytree': [0.7,0.8,0.9,1.0],\n",
    "            'clf__min_child_samples': [40,60,80],\n",
    "            'clf__reg_alpha': np.logspace(-6,-1,6),\n",
    "            'clf__reg_lambda': np.logspace(-3,0,7),\n",
    "            'clf__min_split_gain': [0.0,1e-4,1e-3],\n",
    "        }\n",
    "        return clf, space, 'lgbm'\n",
    "\n",
    "    if mdl == 'xgb' and _has_xgb:\n",
    "        from xgboost import XGBClassifier\n",
    "        clf = XGBClassifier(\n",
    "            objective='multi:softprob',\n",
    "            n_estimators=800,\n",
    "            max_depth=8,\n",
    "            learning_rate=0.05,\n",
    "            subsample=0.9,\n",
    "            colsample_bytree=0.8,\n",
    "            reg_alpha=1e-4,\n",
    "            reg_lambda=1.0,\n",
    "            min_child_weight=3,\n",
    "            gamma=0.0,\n",
    "            tree_method='hist',\n",
    "            device = 'cuda',\n",
    "            random_state=seed,\n",
    "            n_jobs=-1,\n",
    "        )\n",
    "        space = {\n",
    "            'clf__n_estimators': [400,600,800,1000],\n",
    "            'clf__max_depth': [4,6,8,10],\n",
    "            'clf__learning_rate': np.logspace(-2.5, -0.3, 8),\n",
    "            'clf__subsample': [0.7,0.8,0.9,1.0],\n",
    "            'clf__colsample_bytree': [0.6,0.7,0.8,0.9,1.0],\n",
    "            'clf__reg_alpha': np.logspace(-6, -1, 6),\n",
    "            'clf__reg_lambda': np.logspace(-3, 1, 7),\n",
    "            'clf__min_child_weight': [1,3,5,7,10],\n",
    "            'clf__gamma': [0.0, 1e-4, 1e-3, 1e-2],\n",
    "        }\n",
    "        return clf, space, 'xgb'\n",
    "\n",
    "    if mdl == 'et':\n",
    "        clf = ExtraTreesClassifier(\n",
    "            n_estimators=700, random_state=seed, n_jobs=-1,\n",
    "            max_features='sqrt', class_weight='balanced'\n",
    "        )\n",
    "        space = {\n",
    "            'clf__n_estimators': [400,700,1000],\n",
    "            'clf__max_depth': [None, 8, 12, 16, 24],\n",
    "            'clf__min_samples_split': [2, 5, 10, 20],\n",
    "            'clf__min_samples_leaf': [1, 2, 4, 8],\n",
    "            'clf__max_features': ['sqrt', 'log2', 0.5, None],\n",
    "            'clf__bootstrap': [False],  # ET suele ir mejor sin bootstrap\n",
    "        }\n",
    "        return clf, space, 'et'\n",
    "\n",
    "    # RF (fallback por defecto)\n",
    "    clf = RandomForestClassifier(\n",
    "        n_estimators=500, class_weight='balanced', random_state=seed, n_jobs=-1\n",
    "    )\n",
    "    space = {\n",
    "        'clf__n_estimators': [300,500,700,900],\n",
    "        'clf__max_depth': [None,8,12,16,24],\n",
    "        'clf__min_samples_split': [2,5,10,20],\n",
    "        'clf__min_samples_leaf': [1,2,4,8],\n",
    "        'clf__max_features': ['sqrt','log2',0.5,None],\n",
    "        'clf__bootstrap': [True],\n",
    "    }\n",
    "    return clf, space, 'rf'\n",
    "\n",
    "# ========== Threshold tuning (OvR) ==========\n",
    "def _tune_thresholds_ovr(y_tune: np.ndarray, proba_tune: np.ndarray, n_classes: int,\n",
    "                         grid: np.ndarray = None) -> np.ndarray:\n",
    "    if grid is None:\n",
    "        grid = np.linspace(0.1, 0.9, 41)\n",
    "    ths = np.zeros(n_classes)\n",
    "    for c in range(n_classes):\n",
    "        best_f1, best_t = -1.0, 0.5\n",
    "        y_bin = (y_tune == c).astype(int)\n",
    "        p = proba_tune[:, c]\n",
    "        for t in grid:\n",
    "            y_hat = (p >= t).astype(int)\n",
    "            f1 = f1_score(y_bin, y_hat, zero_division=0)\n",
    "            if f1 > best_f1:\n",
    "                best_f1, best_t = f1, t\n",
    "        ths[c] = best_t\n",
    "    return ths\n",
    "\n",
    "def _apply_thresholds(proba: np.ndarray, thresholds: np.ndarray) -> np.ndarray:\n",
    "    scores = proba - thresholds.reshape(1, -1)\n",
    "    return np.argmax(scores, axis=1)\n",
    "\n",
    "# ========== Función principal (CV5 + ablations + tuning + guardado) ==========\n",
    "def run_cv_ablations(\n",
    "    feats: pd.DataFrame,\n",
    "    model: str = 'lgbm',                # ahora: 'lgbm' | 'xgb' | 'rf' | 'et'\n",
    "    feature_set: str = 'all',           # 'hvg' | 'dhvg' | 'whvg' | 'all'\n",
    "    n_splits: int = 5,\n",
    "    n_iter: int = 20,\n",
    "    seed: int = 42,\n",
    "    tune_thresholds: bool = True,\n",
    "    save_prefix: str = None,\n",
    "    save_full: bool = True\n",
    ") -> Dict[str, Any]:\n",
    "    X_df, y, le = _prep_feats_labels(feats, feature_set)\n",
    "    X = X_df.values\n",
    "    classes = le.classes_\n",
    "    feature_names = X_df.columns.tolist()\n",
    "    n_classes = len(classes)\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "    fold_rows, fold_rows_tuned = [], []\n",
    "    confusions, confusions_tuned = [], []\n",
    "    importances_accum = []\n",
    "    oof_pred = np.full_like(y, fill_value=-1)\n",
    "    oof_pred_tuned = np.full_like(y, fill_value=-1)\n",
    "    oof_proba = np.zeros((len(y), n_classes))\n",
    "    oof_proba_tuned = np.zeros((len(y), n_classes))\n",
    "    best_fold = {'score': -np.inf, 'params': None}\n",
    "\n",
    "    with parallel_backend('threading'):\n",
    "        for k, (tr, te) in enumerate(skf.split(X, y), start=1):\n",
    "            clf, space, eff_model = _make_model_and_space(model, seed)\n",
    "            inner_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "            pipe = Pipeline([('imp', SimpleImputer(strategy='median')), ('clf', clf)])\n",
    "            search = RandomizedSearchCV(\n",
    "                pipe, param_distributions=space, n_iter=n_iter, cv=inner_cv,\n",
    "                scoring='f1_macro', n_jobs=-1, random_state=seed, verbose=0, refit=True\n",
    "            )\n",
    "            search.fit(X[tr], y[tr])\n",
    "            best = search.best_estimator_\n",
    "            if search.best_score_ > best_fold['score']:\n",
    "                best_fold = {'score': float(search.best_score_), 'params': search.best_params_}\n",
    "\n",
    "            # tuning interno (20% del train)\n",
    "            if tune_thresholds and hasattr(best, \"predict_proba\"):\n",
    "                sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=seed)\n",
    "                (tr_sub, tune_sub), = sss.split(X[tr], y[tr])\n",
    "                tr_abs = np.array(tr)[tr_sub]; tune_abs = np.array(tr)[tune_sub]\n",
    "\n",
    "                clf2, _, _ = _make_model_and_space(eff_model, seed)\n",
    "                tuned_pipe = Pipeline([('imp', SimpleImputer(strategy='median')), ('clf', clf2)])\n",
    "                tuned_pipe.set_params(**{k: v for k, v in search.best_params_.items()})\n",
    "                tuned_pipe.fit(X[tr_abs], y[tr_abs])\n",
    "\n",
    "                proba_tune = tuned_pipe.predict_proba(X[tune_abs])\n",
    "                ths = _tune_thresholds_ovr(y[tune_abs], proba_tune, n_classes)\n",
    "            else:\n",
    "                ths = np.full(n_classes, 0.5)\n",
    "\n",
    "            # evaluación en test fold\n",
    "            proba_te = best.predict_proba(X[te]) if hasattr(best, \"predict_proba\") else None\n",
    "            y_hat = best.predict(X[te])\n",
    "            f1m = f1_score(y[te], y_hat, average='macro')\n",
    "            acc = accuracy_score(y[te], y_hat)\n",
    "            f1_pc = f1_score(y[te], y_hat, average=None, labels=np.arange(n_classes))\n",
    "            row = {'fold': k, 'f1_macro': f1m, 'accuracy': acc}\n",
    "            for i, cls in enumerate(classes): row[f'F1_{cls}'] = f1_pc[i]\n",
    "            fold_rows.append(row)\n",
    "            cm = confusion_matrix(y[te], y_hat, labels=np.arange(n_classes), normalize='true')\n",
    "            confusions.append(cm)\n",
    "\n",
    "            if proba_te is not None and tune_thresholds:\n",
    "                y_hat_t = _apply_thresholds(proba_te, ths)\n",
    "                f1m_t = f1_score(y[te], y_hat_t, average='macro')\n",
    "                acc_t = accuracy_score(y[te], y_hat_t)\n",
    "                f1_pc_t = f1_score(y[te], y_hat_t, average=None, labels=np.arange(n_classes))\n",
    "                row_t = {'fold': k, 'f1_macro': f1m_t, 'accuracy': acc_t}\n",
    "                for i, cls in enumerate(classes): row_t[f'F1_{cls}'] = f1_pc_t[i]\n",
    "                fold_rows_tuned.append(row_t)\n",
    "                cm_t = confusion_matrix(y[te], y_hat_t, labels=np.arange(n_classes), normalize='true')\n",
    "                confusions_tuned.append(cm_t)\n",
    "\n",
    "            # OOF\n",
    "            oof_pred[te] = y_hat\n",
    "            if proba_te is not None: oof_proba[te] = proba_te\n",
    "            if proba_te is not None and tune_thresholds:\n",
    "                oof_pred_tuned[te] = y_hat_t\n",
    "                oof_proba_tuned[te] = proba_te\n",
    "\n",
    "            # Importancias\n",
    "            try:\n",
    "                imp = best.named_steps['clf'].feature_importances_\n",
    "                if len(imp) == len(feature_names):\n",
    "                    importances_accum.append(imp)\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "    # Agregados\n",
    "    cv_df = pd.DataFrame(fold_rows)\n",
    "    summary = {\n",
    "        'model_used': eff_model.upper(),\n",
    "        'feature_set': feature_set,\n",
    "        'F1_macro_mean': float(cv_df['f1_macro'].mean()),\n",
    "        'F1_macro_std' : float(cv_df['f1_macro'].std(ddof=1)),\n",
    "        'accuracy_mean': float(cv_df['accuracy'].mean()),\n",
    "        'accuracy_std' : float(cv_df['accuracy'].std(ddof=1)),\n",
    "        'cv_best_score_f1_macro': best_fold['score']\n",
    "    }\n",
    "    per_class = []\n",
    "    for i, cls in enumerate(classes):\n",
    "        vals = cv_df[f'F1_{cls}']\n",
    "        per_class.append([cls, float(vals.mean()), float(vals.std(ddof=1))])\n",
    "    per_class_df = pd.DataFrame(per_class, columns=['class','F1_mean','F1_std']).sort_values('F1_mean', ascending=False)\n",
    "    mean_cm = np.mean(np.stack(confusions, axis=0), axis=0)\n",
    "\n",
    "    tuned_available = len(fold_rows_tuned) == n_splits\n",
    "    cv_tuned_df = pd.DataFrame(fold_rows_tuned) if tuned_available else pd.DataFrame()\n",
    "    summary_tuned, per_class_tuned_df, mean_cm_tuned = {}, pd.DataFrame(columns=['class','F1_mean','F1_std']), None\n",
    "    if tuned_available:\n",
    "        summary_tuned = {\n",
    "            'F1_macro_mean_tuned': float(cv_tuned_df['f1_macro'].mean()),\n",
    "            'F1_macro_std_tuned' : float(cv_tuned_df['f1_macro'].std(ddof=1)),\n",
    "            'accuracy_mean_tuned': float(cv_tuned_df['accuracy'].mean()),\n",
    "            'accuracy_std_tuned' : float(cv_tuned_df['accuracy'].std(ddof=1)),\n",
    "        }\n",
    "        per_class_t = []\n",
    "        for i, cls in enumerate(classes):\n",
    "            vals = cv_tuned_df[f'F1_{cls}']\n",
    "            per_class_t.append([cls, float(vals.mean()), float(vals.std(ddof=1))])\n",
    "        per_class_tuned_df = pd.DataFrame(per_class_t, columns=['class','F1_mean','F1_std']).sort_values('F1_mean', ascending=False)\n",
    "        mean_cm_tuned = np.mean(np.stack(confusions_tuned, axis=0), axis=0)\n",
    "\n",
    "    # Importancias en %\n",
    "    feat_imp_df = pd.DataFrame(columns=['feature','mean_%','std_%'])\n",
    "    if importances_accum:\n",
    "        I = np.vstack(importances_accum)\n",
    "        mean_imp = I.mean(axis=0)\n",
    "        std_imp  = I.std(axis=0, ddof=1)\n",
    "        total = mean_imp.sum() if mean_imp.sum() > 0 else 1.0\n",
    "        feat_imp_df = pd.DataFrame({\n",
    "            'feature': feature_names,\n",
    "            'mean_%': 100.0 * mean_imp / total,\n",
    "            'std_%' : 100.0 * std_imp  / total\n",
    "        }).sort_values('mean_%', ascending=False)\n",
    "\n",
    "    # Guardado\n",
    "    artifacts = {}\n",
    "    if save_prefix:\n",
    "        os.makedirs(os.path.dirname(save_prefix) or \".\", exist_ok=True)\n",
    "        # OOF sin tuning\n",
    "        oof_df = pd.DataFrame({\n",
    "            'ID': feats['ID'].astype(str).values if 'ID' in feats.columns else np.arange(len(y)).astype(str),\n",
    "            'y_true': feats['Classification'].astype(str).values,\n",
    "            'y_pred': per_class_df['class'].values[0]  # placeholder; sobrescrito abajo\n",
    "        })\n",
    "        oof_df['y_pred'] = pd.Series(oof_pred).map(lambda k: le.inverse_transform([k])[0])\n",
    "        for j, cls in enumerate(classes):\n",
    "            oof_df[f'proba_{cls}'] = oof_proba[:, j]\n",
    "        path_oof = f\"{save_prefix}_oof.csv\"; oof_df.to_csv(path_oof, index=False)\n",
    "        artifacts['oof_path'] = path_oof\n",
    "\n",
    "        # OOF tuned\n",
    "        if tuned_available:\n",
    "            oof_t_df = pd.DataFrame({\n",
    "                'ID': oof_df['ID'],\n",
    "                'y_true': oof_df['y_true'],\n",
    "                'y_pred_tuned': pd.Series(oof_pred_tuned).map(lambda k: le.inverse_transform([k])[0])\n",
    "            })\n",
    "            for j, cls in enumerate(classes):\n",
    "                oof_t_df[f'proba_{cls}'] = oof_proba_tuned[:, j]\n",
    "            path_oof_t = f\"{save_prefix}_oof_tuned.csv\"; oof_t_df.to_csv(path_oof_t, index=False)\n",
    "            artifacts['oof_tuned_path'] = path_oof_t\n",
    "\n",
    "        # Folds JSON\n",
    "        fold_json = {\n",
    "            'summary': summary, 'summary_tuned': summary_tuned,\n",
    "            'folds': cv_df.to_dict(orient='records'),\n",
    "            'folds_tuned': (cv_tuned_df.to_dict(orient='records') if tuned_available else []),\n",
    "            'classes': classes.tolist(),\n",
    "            'feature_set': feature_set, 'model': summary['model_used']\n",
    "        }\n",
    "        path_folds = f\"{save_prefix}_folds.json\"\n",
    "        with open(path_folds, \"w\", encoding=\"utf-8\") as f: json.dump(fold_json, f, indent=2)\n",
    "        artifacts['folds_json'] = path_folds\n",
    "\n",
    "        # Full model con mejores params del mejor fold\n",
    "        if save_full and best_fold['params'] is not None:\n",
    "            clf_full, _, eff = _make_model_and_space(summary['model_used'], seed)\n",
    "            pipe_full = Pipeline([('imp', SimpleImputer(strategy='median')), ('clf', clf_full)])\n",
    "            pipe_full.set_params(**best_fold['params'])\n",
    "            pipe_full.fit(X, y)\n",
    "            path_model = f\"{save_prefix}_full_model.joblib\"\n",
    "            joblib_dump(pipe_full, path_model)\n",
    "            artifacts['full_model_path'] = path_model\n",
    "\n",
    "            proba_all = pipe_full.predict_proba(X)\n",
    "            yhat_all = pipe_full.predict(X)\n",
    "            all_df = pd.DataFrame({\n",
    "                'ID': feats['ID'].astype(str).values if 'ID' in feats.columns else np.arange(len(y)).astype(str),\n",
    "                'y_true': feats['Classification'].astype(str).values,\n",
    "                'y_pred': le.inverse_transform(yhat_all)\n",
    "            })\n",
    "            for j, cls in enumerate(classes):\n",
    "                all_df[f'proba_{cls}'] = proba_all[:, j]\n",
    "            path_all = f\"{save_prefix}_full_all_preds.csv\"\n",
    "            all_df.to_csv(path_all, index=False)\n",
    "            artifacts['full_all_preds_path'] = path_all\n",
    "\n",
    "    return {\n",
    "        'summary': summary,\n",
    "        'summary_tuned': summary_tuned,\n",
    "        'per_class': per_class_df,\n",
    "        'per_class_tuned': per_class_tuned_df,\n",
    "        'mean_cm': mean_cm,\n",
    "        'mean_cm_tuned': mean_cm_tuned,\n",
    "        'feat_importances_%': feat_imp_df,\n",
    "        'artifacts': artifacts\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b68fe10a-2cc0-4bd2-b78a-fa46f1b211ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run 1: LGBM con TODAS las features de grafos, thresholds activados\n",
    "res_all_lgbm = run_cv_ablations(\n",
    "    feats,\n",
    "    model='lgbm',\n",
    "    feature_set='all',       # 'hvg' | 'dhvg' | 'whvg' | 'all'\n",
    "    n_splits=5,\n",
    "    n_iter=20,\n",
    "    seed=42,\n",
    "    tune_thresholds=True,\n",
    "    save_prefix=\"vg_cv/run_lgbm_all\",   # carpeta+prefijo (se crean CSV/JSON/MODEL)\n",
    "    save_full=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cab69a2f-e15d-4202-990e-5704007755c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run 2: LGBM con TODAS las features de grafos, thresholds activados, solo WHVG\n",
    "res_all_lgbm_whvg = run_cv_ablations(\n",
    "    feats,\n",
    "    model='lgbm',\n",
    "    feature_set='whvg',       # 'hvg' | 'dhvg' | 'whvg' | 'all'\n",
    "    n_splits=5,\n",
    "    n_iter=20,\n",
    "    seed=42,\n",
    "    tune_thresholds=True,\n",
    "    save_prefix=\"vg_cv/run_lgbm_all_whvg\",   # carpeta+prefijo (se crean CSV/JSON/MODEL)\n",
    "    save_full=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d5e54d5-d2a3-458e-b8e2-b7690dd45049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run 3: RF con TODAS las features de grafos, thresholds activados\n",
    "res_all_rf = run_cv_ablations(\n",
    "    feats,\n",
    "    model='rf',\n",
    "    feature_set='all',       # 'hvg' | 'dhvg' | 'whvg' | 'all'\n",
    "    n_splits=5,\n",
    "    n_iter=20,\n",
    "    seed=42,\n",
    "    tune_thresholds=True,\n",
    "    save_prefix=\"vg_cv/run_rf_all\",   # carpeta+prefijo (se crean CSV/JSON/MODEL)\n",
    "    save_full=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41fe6f82-3b6f-4edf-841b-3e7d01867457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run 4: RF con TODAS las features de grafos, thresholds activados, solo WHVG\n",
    "res_all_rf_whvg = run_cv_ablations(\n",
    "    feats,\n",
    "    model='rf',\n",
    "    feature_set='whvg',       # 'hvg' | 'dhvg' | 'whvg' | 'all'\n",
    "    n_splits=5,\n",
    "    n_iter=20,\n",
    "    seed=42,\n",
    "    tune_thresholds=True,\n",
    "    save_prefix=\"vg_cv/run_rf_all_whvg\",   # carpeta+prefijo (se crean CSV/JSON/MODEL)\n",
    "    save_full=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d91770ee-3676-45ca-aee8-10e510524dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run 5: XGBoost con TODAS las features de grafos, thresholds activados\n",
    "res_all_xgb = run_cv_ablations(\n",
    "    feats,\n",
    "    model='xgb',\n",
    "    feature_set='all',       # 'hvg' | 'dhvg' | 'whvg' | 'all'\n",
    "    n_splits=5,\n",
    "    n_iter=20,\n",
    "    seed=42,\n",
    "    tune_thresholds=True,\n",
    "    save_prefix=\"vg_cv/run_xgb_all\",   # carpeta+prefijo (se crean CSV/JSON/MODEL)\n",
    "    save_full=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffa0bc34-61e3-4d46-b7ba-e35bbde8c75e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Run 6: RF con TODAS las features de grafos, thresholds activados, solo WHVG\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m res_all_xgb_whvg \u001b[38;5;241m=\u001b[39m \u001b[43mrun_cv_ablations\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mxgb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwhvg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;66;43;03m# 'hvg' | 'dhvg' | 'whvg' | 'all'\u001b[39;49;00m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtune_thresholds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvg_cv/run_xgb_all_whvg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# carpeta+prefijo (se crean CSV/JSON/MODEL)\u001b[39;49;00m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_full\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m     12\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 203\u001b[0m, in \u001b[0;36mrun_cv_ablations\u001b[1;34m(feats, model, feature_set, n_splits, n_iter, seed, tune_thresholds, save_prefix, save_full)\u001b[0m\n\u001b[0;32m    198\u001b[0m pipe \u001b[38;5;241m=\u001b[39m Pipeline([(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimp\u001b[39m\u001b[38;5;124m'\u001b[39m, SimpleImputer(strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmedian\u001b[39m\u001b[38;5;124m'\u001b[39m)), (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclf\u001b[39m\u001b[38;5;124m'\u001b[39m, clf)])\n\u001b[0;32m    199\u001b[0m search \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(\n\u001b[0;32m    200\u001b[0m     pipe, param_distributions\u001b[38;5;241m=\u001b[39mspace, n_iter\u001b[38;5;241m=\u001b[39mn_iter, cv\u001b[38;5;241m=\u001b[39minner_cv,\n\u001b[0;32m    201\u001b[0m     scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1_macro\u001b[39m\u001b[38;5;124m'\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, random_state\u001b[38;5;241m=\u001b[39mseed, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, refit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    202\u001b[0m )\n\u001b[1;32m--> 203\u001b[0m \u001b[43msearch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtr\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtr\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    204\u001b[0m best \u001b[38;5;241m=\u001b[39m search\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m search\u001b[38;5;241m.\u001b[39mbest_score_ \u001b[38;5;241m>\u001b[39m best_fold[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n",
      "File \u001b[1;32mc:\\Users\\Gsus\\Desktop\\Prog\\Mantra\\env\\lib\\site-packages\\sklearn\\base.py:1365\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1358\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1360\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1361\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1362\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1363\u001b[0m     )\n\u001b[0;32m   1364\u001b[0m ):\n\u001b[1;32m-> 1365\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Gsus\\Desktop\\Prog\\Mantra\\env\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1051\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1045\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m   1046\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m   1047\u001b[0m     )\n\u001b[0;32m   1049\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m-> 1051\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1053\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m   1054\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m   1055\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Gsus\\Desktop\\Prog\\Mantra\\env\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1992\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1990\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1991\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1992\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1993\u001b[0m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1994\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\n\u001b[0;32m   1995\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1996\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Gsus\\Desktop\\Prog\\Mantra\\env\\lib\\site-packages\\sklearn\\model_selection\\_search.py:997\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    989\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    990\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    991\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    992\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    993\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    994\u001b[0m         )\n\u001b[0;32m    995\u001b[0m     )\n\u001b[1;32m--> 997\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    998\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    999\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1000\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1001\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1002\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1003\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1004\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1005\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1006\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1007\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1008\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1009\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1010\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1011\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1012\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1013\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1015\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1016\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1017\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1018\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1019\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1020\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Gsus\\Desktop\\Prog\\Mantra\\env\\lib\\site-packages\\sklearn\\utils\\parallel.py:82\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     73\u001b[0m warning_filters \u001b[38;5;241m=\u001b[39m warnings\u001b[38;5;241m.\u001b[39mfilters\n\u001b[0;32m     74\u001b[0m iterable_with_config_and_warning_filters \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     75\u001b[0m     (\n\u001b[0;32m     76\u001b[0m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     81\u001b[0m )\n\u001b[1;32m---> 82\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Gsus\\Desktop\\Prog\\Mantra\\env\\lib\\site-packages\\joblib\\parallel.py:2072\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2066\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2067\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2068\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2069\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2070\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Gsus\\Desktop\\Prog\\Mantra\\env\\lib\\site-packages\\joblib\\parallel.py:1682\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1679\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1681\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1682\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1684\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1685\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1686\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1687\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1688\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Gsus\\Desktop\\Prog\\Mantra\\env\\lib\\site-packages\\joblib\\parallel.py:1800\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1789\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_ordered:\n\u001b[0;32m   1790\u001b[0m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[0;32m   1791\u001b[0m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1795\u001b[0m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[0;32m   1796\u001b[0m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[0;32m   1797\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   1798\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING\n\u001b[0;32m   1799\u001b[0m     ):\n\u001b[1;32m-> 1800\u001b[0m         \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1801\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1803\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1804\u001b[0m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[0;32m   1805\u001b[0m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1811\u001b[0m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[0;32m   1812\u001b[0m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Run 6: RF con TODAS las features de grafos, thresholds activados, solo WHVG\n",
    "res_all_xgb_whvg = run_cv_ablations(\n",
    "    feats,\n",
    "    model='xgb',\n",
    "    feature_set='whvg',       # 'hvg' | 'dhvg' | 'whvg' | 'all'\n",
    "    n_splits=5,\n",
    "    n_iter=20,\n",
    "    seed=42,\n",
    "    tune_thresholds=True,\n",
    "    save_prefix=\"vg_cv/run_xgb_all_whvg\",   # carpeta+prefijo (se crean CSV/JSON/MODEL)\n",
    "    save_full=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e07af49-5e02-4972-b1d7-c90997b01d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run 7: ExtraTrees con TODAS las features de grafos, thresholds activados\n",
    "res_all_et = run_cv_ablations(\n",
    "    feats,\n",
    "    model='et',\n",
    "    feature_set='all',       # 'hvg' | 'dhvg' | 'whvg' | 'all'\n",
    "    n_splits=5,\n",
    "    n_iter=20,\n",
    "    seed=42,\n",
    "    tune_thresholds=True,\n",
    "    save_prefix=\"vg_cv/run_et_all\",   # carpeta+prefijo (se crean CSV/JSON/MODEL)\n",
    "    save_full=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1bc3cc8-c7f0-4589-9381-48200424731a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run 8: ExtraTrees con TODAS las features de grafos, thresholds activados, solo WHVG\n",
    "res_all_et_whvg = run_cv_ablations(\n",
    "    feats,\n",
    "    model='et',\n",
    "    feature_set='whvg',       # 'hvg' | 'dhvg' | 'whvg' | 'all'\n",
    "    n_splits=5,\n",
    "    n_iter=20,\n",
    "    seed=42,\n",
    "    tune_thresholds=True,\n",
    "    save_prefix=\"vg_cv/run_et_all_whvg\",   # carpeta+prefijo (se crean CSV/JSON/MODEL)\n",
    "    save_full=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf9b033-7456-4b58-9f0b-8399d9ef9c76",
   "metadata": {},
   "source": [
    "## Printing results...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "160ce1bb-9a7d-4e06-84b8-fc4d5a80e8fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Resumen (sin tuning) ==\n",
      "{'model_used': 'LGBM', 'feature_set': 'all', 'F1_macro_mean': 0.6222757623095071, 'F1_macro_std': 0.009848925503454748, 'accuracy_mean': 0.6611891409854057, 'accuracy_std': 0.010120881265417263, 'cv_best_score_f1_macro': 0.6274006061181532}\n",
      "== Resumen (sin tuning) ==\n",
      "{'model_used': 'LGBM', 'feature_set': 'whvg', 'F1_macro_mean': 0.6045730338366404, 'F1_macro_std': 0.009762040029579012, 'accuracy_mean': 0.6477148393956542, 'accuracy_std': 0.011942188158526193, 'cv_best_score_f1_macro': 0.6174340114622083}\n",
      "== Resumen (sin tuning) ==\n",
      "{'model_used': 'RF', 'feature_set': 'all', 'F1_macro_mean': 0.6051874889168729, 'F1_macro_std': 0.018298600641430705, 'accuracy_mean': 0.6588430999296873, 'accuracy_std': 0.018323616295367173, 'cv_best_score_f1_macro': 0.6149322348204496}\n",
      "== Resumen (sin tuning) ==\n",
      "{'model_used': 'RF', 'feature_set': 'whvg', 'F1_macro_mean': 0.605867641520154, 'F1_macro_std': 0.03010911965625042, 'accuracy_mean': 0.6582703092040952, 'accuracy_std': 0.02189187011852591, 'cv_best_score_f1_macro': 0.6162379338902589}\n",
      "== Resumen (sin tuning) ==\n",
      "{'model_used': 'XGB', 'feature_set': 'all', 'F1_macro_mean': 0.6046819639241308, 'F1_macro_std': 0.036055459670747546, 'accuracy_mean': 0.6588482447565639, 'accuracy_std': 0.030695001342389068, 'cv_best_score_f1_macro': 0.615357815476423}\n",
      "== Resumen (sin tuning) ==\n",
      "{'model_used': 'XGB', 'feature_set': 'whvg', 'F1_macro_mean': 0.6113199522843555, 'F1_macro_std': 0.023299865548631244, 'accuracy_mean': 0.656507348527722, 'accuracy_std': 0.021566875897036455, 'cv_best_score_f1_macro': 0.6098268347843272}\n",
      "== Resumen (sin tuning) ==\n",
      "{'model_used': 'ET', 'feature_set': 'all', 'F1_macro_mean': 0.6066404596714519, 'F1_macro_std': 0.035095555889062525, 'accuracy_mean': 0.648311639313337, 'accuracy_std': 0.018483885582526248, 'cv_best_score_f1_macro': 0.615995096302429}\n",
      "== Resumen (sin tuning) ==\n",
      "{'model_used': 'ET', 'feature_set': 'whvg', 'F1_macro_mean': 0.6172022053413059, 'F1_macro_std': 0.03235656182427716, 'accuracy_mean': 0.6611994306391589, 'accuracy_std': 0.025465924107092863, 'cv_best_score_f1_macro': 0.6278633841536576}\n",
      "\n",
      "== Resumen (tuned) ==\n",
      "{'F1_macro_mean_tuned': 0.6061735230337015, 'F1_macro_std_tuned': 0.018897036210874463, 'accuracy_mean_tuned': 0.6447857179605905, 'accuracy_std_tuned': 0.004044566963650298}\n",
      "\n",
      "== Resumen (tuned) ==\n",
      "{'F1_macro_mean_tuned': 0.5997817903742657, 'F1_macro_std_tuned': 0.019157871673357064, 'accuracy_mean_tuned': 0.6389206153212943, 'accuracy_std_tuned': 0.011825796143605382}\n",
      "\n",
      "== Resumen (tuned) ==\n",
      "{'F1_macro_mean_tuned': 0.6051634641377307, 'F1_macro_std_tuned': 0.033590529851287104, 'accuracy_mean_tuned': 0.6518221261854538, 'accuracy_std_tuned': 0.025422816680106354}\n",
      "\n",
      "== Resumen (tuned) ==\n",
      "{'F1_macro_mean_tuned': 0.6050933050211651, 'F1_macro_std_tuned': 0.045265274757738096, 'accuracy_mean_tuned': 0.6594467596165389, 'accuracy_std_tuned': 0.029789720012550248}\n",
      "\n",
      "== Resumen (tuned) ==\n",
      "{'F1_macro_mean_tuned': 0.6039283327796836, 'F1_macro_std_tuned': 0.022744573467033593, 'accuracy_mean_tuned': 0.6500591655090806, 'accuracy_std_tuned': 0.01972004155414724}\n",
      "\n",
      "== Resumen (tuned) ==\n",
      "{'F1_macro_mean_tuned': 0.5947686103289935, 'F1_macro_std_tuned': 0.02364044827357532, 'accuracy_mean_tuned': 0.6430210423419251, 'accuracy_std_tuned': 0.02214812416398762}\n",
      "\n",
      "== Resumen (tuned) ==\n",
      "{'F1_macro_mean_tuned': 0.6028962940923195, 'F1_macro_std_tuned': 0.034539752873060596, 'accuracy_mean_tuned': 0.6488947196926823, 'accuracy_std_tuned': 0.011647961397973392}\n",
      "\n",
      "== Resumen (tuned) ==\n",
      "{'F1_macro_mean_tuned': 0.6033157346312787, 'F1_macro_std_tuned': 0.04230349204270121, 'accuracy_mean_tuned': 0.6541715971257567, 'accuracy_std_tuned': 0.030396650905539543}\n"
     ]
    }
   ],
   "source": [
    "for i in [res_all_lgbm,res_all_lgbm_whvg,res_all_rf,res_all_rf_whvg,res_all_xgb,res_all_xgb_whvg,res_all_et,res_all_et_whvg]:\n",
    "    # Inspección rápida\n",
    "    print(\"== Resumen (sin tuning) ==\")\n",
    "    print(i['summary'])\n",
    "for i in [res_all_lgbm,res_all_lgbm_whvg,res_all_rf,res_all_rf_whvg,res_all_xgb,res_all_xgb_whvg,res_all_et,res_all_et_whvg]:\n",
    "    # Inspección rápida\n",
    "    print(\"\\n== Resumen (tuned) ==\")\n",
    "    print(i['summary_tuned'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a4ef27b2-74d7-4bb2-8765-94fbe0ab580f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>F1_mean</th>\n",
       "      <th>F1_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Non-Tr.</td>\n",
       "      <td>0.969022</td>\n",
       "      <td>0.011659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CV</td>\n",
       "      <td>0.791020</td>\n",
       "      <td>0.041315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HPM</td>\n",
       "      <td>0.756221</td>\n",
       "      <td>0.108801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AGN</td>\n",
       "      <td>0.584312</td>\n",
       "      <td>0.031920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Other</td>\n",
       "      <td>0.471408</td>\n",
       "      <td>0.047054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Flare</td>\n",
       "      <td>0.438745</td>\n",
       "      <td>0.119471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Blazar</td>\n",
       "      <td>0.424627</td>\n",
       "      <td>0.043738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SN</td>\n",
       "      <td>0.401231</td>\n",
       "      <td>0.059285</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     class   F1_mean    F1_std\n",
       "5  Non-Tr.  0.969022  0.011659\n",
       "2       CV  0.791020  0.041315\n",
       "4      HPM  0.756221  0.108801\n",
       "0      AGN  0.584312  0.031920\n",
       "6    Other  0.471408  0.047054\n",
       "3    Flare  0.438745  0.119471\n",
       "1   Blazar  0.424627  0.043738\n",
       "7       SN  0.401231  0.059285"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_all_lgbm_whvg['per_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e2ed3805-8873-4bcb-9a4c-8fef9b21ed4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.636012</td>\n",
       "      <td>0.044246</td>\n",
       "      <td>0.019048</td>\n",
       "      <td>0.085565</td>\n",
       "      <td>0.006349</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003175</td>\n",
       "      <td>0.205605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.158824</td>\n",
       "      <td>0.394118</td>\n",
       "      <td>0.188235</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005882</td>\n",
       "      <td>0.047059</td>\n",
       "      <td>0.147059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.038595</td>\n",
       "      <td>0.064502</td>\n",
       "      <td>0.791342</td>\n",
       "      <td>0.017982</td>\n",
       "      <td>0.005128</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033400</td>\n",
       "      <td>0.049051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.249507</td>\n",
       "      <td>0.027833</td>\n",
       "      <td>0.041626</td>\n",
       "      <td>0.437685</td>\n",
       "      <td>0.048768</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006897</td>\n",
       "      <td>0.187685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.020113</td>\n",
       "      <td>0.003390</td>\n",
       "      <td>0.003390</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>0.946271</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.111765</td>\n",
       "      <td>0.179739</td>\n",
       "      <td>0.192157</td>\n",
       "      <td>0.011111</td>\n",
       "      <td>0.011111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.403268</td>\n",
       "      <td>0.090850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.305604</td>\n",
       "      <td>0.079614</td>\n",
       "      <td>0.070531</td>\n",
       "      <td>0.097005</td>\n",
       "      <td>0.004444</td>\n",
       "      <td>0.004444</td>\n",
       "      <td>0.017778</td>\n",
       "      <td>0.420580</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.636012  0.044246  0.019048  0.085565  0.006349  0.000000  0.003175   \n",
       "1  0.158824  0.394118  0.188235  0.058824  0.000000  0.005882  0.047059   \n",
       "2  0.038595  0.064502  0.791342  0.017982  0.005128  0.000000  0.033400   \n",
       "3  0.249507  0.027833  0.041626  0.437685  0.048768  0.000000  0.006897   \n",
       "4  0.120000  0.000000  0.040000  0.080000  0.720000  0.000000  0.000000   \n",
       "5  0.020113  0.003390  0.003390  0.003333  0.003333  0.946271  0.000000   \n",
       "6  0.111765  0.179739  0.192157  0.011111  0.011111  0.000000  0.403268   \n",
       "7  0.305604  0.079614  0.070531  0.097005  0.004444  0.004444  0.017778   \n",
       "\n",
       "          7  \n",
       "0  0.205605  \n",
       "1  0.147059  \n",
       "2  0.049051  \n",
       "3  0.187685  \n",
       "4  0.040000  \n",
       "5  0.020169  \n",
       "6  0.090850  \n",
       "7  0.420580  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(res_all_lgbm_whvg['mean_cm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c761bca-46f4-41ea-9dae-53509ac7697c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Platform 0] NVIDIA CUDA\n",
      "   [Device 0] NVIDIA GeForce RTX 4070 SUPER\n",
      "      Type: ALL | GPU\n",
      "      Max Compute Units: 56\n",
      "      Global Memory (MB): 12282\n",
      "\n",
      "[Platform 1] AMD Accelerated Parallel Processing\n",
      "   [Device 0] gfx1036\n",
      "      Type: ALL | GPU\n",
      "      Max Compute Units: 1\n",
      "      Global Memory (MB): 12263\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
