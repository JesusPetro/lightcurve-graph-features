# Graph-Based Light-Curve Features for Robust Transient Classification

This repository contains the implementation code associated with the paper **"Graph-Based Light-Curve Features for Robust Transient Classification"**.  
All content is provided in Jupyter Notebooks (`.ipynb`), organized into logical sections for easier exploration and understanding.

---

## ğŸ“ Repository structure

```
    lightcurve-graph-features/
    â”œâ”€â”€ Code/
    â”‚   â”œâ”€â”€ 001-Reading_files.ipynb
    â”‚   â”œâ”€â”€ 002-Extranting_features.ipynb
    â”‚   â”œâ”€â”€ 004-Rerun_models.ipynb
    â”‚   â”œâ”€â”€ 005-Evaluating_models.ipynb
    â”‚   â””â”€â”€ vg_mantra.py
    â”œâ”€â”€ data/
    â”‚   â””â”€â”€ README.md
    â”œâ”€â”€ figures/
    â”‚   â”œâ”€â”€ CM_counts.pdf
    â”‚   â”œâ”€â”€ CM_percentaje.pdf
    â”‚   â”œâ”€â”€ PR-AUC.pdf
    â”‚   â””â”€â”€ Top_feature_importances.pdf
    â”œâ”€â”€ res/
    â”‚   â”œâ”€â”€ Features_extraction_Mantra.csv
    â”‚   â”œâ”€â”€ transient_labels2.csv
    â”‚   â”œâ”€â”€ transient_lightcurves_v2.csv
    â”‚   â””â”€â”€ transient_lightcurves_v2_filtered.csv
    â”œâ”€â”€ vg_cv/
    â”‚   â”œâ”€â”€ et_all/
    â”‚   â”œâ”€â”€ et_all_whvg/
    â”‚   â”œâ”€â”€ lgbm_all/
    â”‚   â”œâ”€â”€ lgbm_all_whvg/
    â”‚   â”œâ”€â”€ rf_all/
    â”‚   â”œâ”€â”€ rf_all_whvg/
    â”‚   â”œâ”€â”€ xgb_all/
    â”‚   â””â”€â”€ xgb_all_whvg/
    â”œâ”€â”€ README.md
    â””â”€â”€ requirements.txt
```

> âš ï¸ **Note:** Some paths used inside notebooks may require adaptation to your local environment.

---

## âš™ï¸ Installation

1. **Clone the repository:**

   ```bash
   git clone https://github.com/JesusPetro/lightcurve-graph-features.git
   cd lightcurve-graph-features
   ```

2. **Create a virtual environment (recommended):**

   ```bash
   python -m venv venv
   source venv/bin/activate   # On Windows: venv\Scripts\activate
   ```

3. **Install dependencies:**
   ```bash
   pip install -r requirements.txt
   ```

---

## ğŸ§© Main Requirements

The project relies on the following key libraries:

- **Data Science:** `numpy`, `pandas`, `scikit-learn`, `scipy`
- **Visualization:** `matplotlib`, `seaborn`, `SciencePlots`
- **Machine Learning Models:** `xgboost`, `lightgbm`
- **Support & Utilities:** `networkx`, `pyopencl`, `pytools`

> Refer to `requirements.txt` for the complete list of dependencies.

---

## ğŸš€ Usage

1. Open the notebooks using **Jupyter Lab** or **VS Code**.
2. Run the notebooks in the following order:

   - `001-Reading_files.ipynb` â†’ Data loading.
   - `002-Extranting_features.ipynb` â†’ Graph-based feature extraction.
   - `004-Rerun_models.ipynb` â†’ Model training and evaluation.
   - `005-Evaluating_models.ipynb` â†’ Metrics analysis and visualization.

3. The generated figures, metrics, and model outputs are stored in `figures/` and `vg_cv/` folders.

---

## ğŸ“Š Results

Key results include:

- **Performance Metrics:** PR-AUC, Confusion Matrix (counts and percentages).
- **Feature Importance:** Top-ranked features obtained
- **Visualizations:** Precision-Recall curves and confusion matrix plots.

---

## ğŸ‘¨â€ğŸ’» Author

**Lead Author:** David Sierra Porta\
**Contact:** dporta@utb.edu.co  
**Institution:** Universidad TecnolÃ³gica de BolÃ­var
